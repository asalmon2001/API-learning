{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ed5003-0fc7-46bf-8d23-a04c74483791",
   "metadata": {},
   "source": [
    "# Welcome\n",
    "\n",
    "We are going to be gathering weather data from the past year and throwing it into an SQLite database.\n",
    "I realized on v1 that I was just throwing away data. Not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2e14ed-b079-4708-95be-a65d9ae65705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4747e6f-3849-4a5f-800e-bec85ac36887",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = 'C:/Users/asalm/My_Drive/Github Repos/Secrets'\n",
    "key_file = open(key_path + '/weatherapi.txt', 'r')\n",
    "api_key = key_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8bfd88-944b-43fd-89d3-0660944f3caa",
   "metadata": {},
   "source": [
    "Lets check what historical data we can get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bcfe4-eef3-4816-928c-1ccb7f465633",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'key':api_key , 'q':'Calgary', 'dt':'2023-09-14' }\n",
    "sample_response = requests.get('http://api.weatherapi.com/v1/history.json', params=params)\n",
    "print(sample_response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2d61e-dee3-4a52-a1a4-d8092694a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(obj=sample_response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ee2d0-05f8-4c99-930f-efb3440e2ce4",
   "metadata": {},
   "source": [
    "Lets think about what tables we want.\n",
    "1. Forecast_hourly_data\n",
    "   Columns: hour_id (ie. 23091403), *all the columns in each hour (minus condition: that we will just keep the code)\n",
    "3. Forecast_day_data\n",
    "4. Astro_data\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01fb654-f065-460b-a87d-442b3b50384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3 as sl\n",
    "connection = sl.connect('weather_v2_database.db')\n",
    "print(connection.total_changes)\n",
    "\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8499ddb-0270-421e-a084-8339ba781fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion(element) :\n",
    "    return '\\'' + str(element) + '\\''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e2461-d6ac-4ccd-bb68-9eb452f27e9e",
   "metadata": {},
   "source": [
    "# Table Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d7097f-21f1-488d-9bbf-72fba49db3e2",
   "metadata": {},
   "source": [
    "## Hourly Weather Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e22ef-15ef-45b5-8722-1615914f3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce all the column names from the json\n",
    "\n",
    "# sample_hourly = sample_response.json()['forecast']['forecastday'][0]['hour']\n",
    "# column_names = ['hour_id', 'day_id']\n",
    "# key_value_list = list(sample_hourly[0].items())\n",
    "# for key, value in key_value_list[1:5] :\n",
    "#     column_names.append(key)\n",
    "# for key, value in key_value_list[6:] :\n",
    "#     column_names.append(key)\n",
    "# column_names.append('condition_text')\n",
    "# column_names.append('condition_code')\n",
    "\n",
    "# df = pd.DataFrame(column_names)\n",
    "# df.to_csv('hourly_weather_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb7e4b40-177a-4afe-a790-edcd1e76b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHourlyWeatherColumnNames() :\n",
    "    dataframe = pd.read_csv('hourly_weather_columns.csv')\n",
    "    my_list = dataframe['0'].values.tolist()[:]\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8019dd-954c-4613-a524-f5b5200e1210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hour_id', 'day_id', 'time', 'temp_c', 'temp_f', 'is_day', 'wind_mph', 'wind_kph', 'wind_degree', 'wind_dir', 'pressure_mb', 'pressure_in', 'precip_mm', 'precip_in', 'humidity', 'cloud', 'feelslike_c', 'feelslike_f', 'windchill_c', 'windchill_f', 'heatindex_c', 'heatindex_f', 'dewpoint_c', 'dewpoint_f', 'will_it_rain', 'chance_of_rain', 'will_it_snow', 'chance_of_snow', 'vis_km', 'vis_miles', 'gust_mph', 'gust_kph', 'uv', 'condition_text', 'condition_code']\n"
     ]
    }
   ],
   "source": [
    "print(getHourlyWeatherColumnNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3662b6-803c-400d-a98c-be98e064ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteHourlyWeatherTable() :\n",
    "    try:\n",
    "        cursor.execute('DROP TABLE hourly_weather')\n",
    "    except:\n",
    "        print('TABLE hourly_weather DOES NOT EXIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954b04a6-f9f5-4cf4-9517-22763f3022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the database\n",
    "def printHourlyWeather() :\n",
    "    rows = cursor.execute('SELECT * FROM hourly_weather').fetchall()\n",
    "    print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d9660e-b1d0-42aa-bee8-af454aa19aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hourly_weather table\n",
    "def startHourlyWeatherTable() :\n",
    "    column_names = getHourlyWeatherColumnNames()\n",
    "    command = 'CREATE TABLE hourly_weather ( ' + ', '.join(list(map(conversion, column_names))) + ')'\n",
    "    \n",
    "    deleteHourlyWeatherTable()\n",
    "    cursor.execute(command)\n",
    "    printHourlyWeather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1060df0-30dd-498a-ab83-2053bb6a7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how I will format the hour_id\n",
    "def getIdsAndTime(hour) :\n",
    "    my_datetime = datetime.fromisoformat(hour['time'])\n",
    "    [day_id, hour_id, time] = my_datetime.strftime('%y%m%d-%y%m%d%H-%H:%M').split('-')\n",
    "    return [hour_id, day_id, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433c090d-d747-43f6-9d61-64433869dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertHourlyData(hour) :\n",
    "    insertion_values = getIdsAndTime(hour)\n",
    "    keys_list = list(hour.keys())\n",
    "    values_list = list(hour.values())\n",
    "    insertion_values = insertion_values + values_list[2:5]\n",
    "    insertion_values = insertion_values + values_list[6:]\n",
    "    insertion_values.append(values_list[5]['text'])\n",
    "    insertion_values.append(values_list[5]['code'])\n",
    "    command = 'INSERT INTO hourly_weather VALUES (' + ', '.join(list(map(conversion, insertion_values))) + ')'\n",
    "    cursor.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e10dce-0741-454b-9f8d-9d3371698970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_hourly = sample_response.json()['forecast']['forecastday'][0]['hour']\n",
    "# #for hour in sample_hourly :\n",
    "# #    insertHourlyData(hour)\n",
    "# startHourlyWeatherTable()\n",
    "# for hour in sample_hourly :\n",
    "#     insertHourlyData(hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae778a95-fab8-438e-a810-5d004b155221",
   "metadata": {},
   "source": [
    "We now have a way to insert an entire day of hourly data into the hourly_weather table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "219cd7fe-7014-476e-819c-fa898adc48ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM hourly_weather': no such table: hourly_weather",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:2266\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2266\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: hourly_weather",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM hourly_weather\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mtail()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:486\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:2330\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2321\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2328\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2330\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2331\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:2278\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2277\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2278\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM hourly_weather': no such table: hourly_weather"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_query('SELECT * FROM hourly_weather', connection)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f72a0-11c6-4a06-a1bc-ca0fb670cb91",
   "metadata": {},
   "source": [
    "## Day Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5566b0-81b7-4cee-a30a-dceed6ea6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_day = sample_response.json()['forecast']['forecastday'][0]\n",
    "print(sample_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd4b32-cfb6-4114-a277-4eb592852cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
